SusanTask, Color Sensor, Auto Code, Other Sensors
Incorporate actual pneumatics code
Color sensor! Learn how to wire it and test using it to get a response
Automate hatch pick up and drop off:
	Pick up:
		Using the limelight, get the angle offset from the pickup location and get the distance away
			Angle offset is given to us
			We will have to do some math/testing to find the distance, but we can't do that yet
			For now just write the logic using a placeholder distance variable
		We can also investigate using the turret lock (see below)
	Drop off:
		**if using hatch v1 (non pneumatics) then we need to drift into the wall**
		**if using hatch v2 (pneumatics) then we can just line up with the light sensor**
		Starts from front of cargo bay
		Move lazy susan to the correct side (hopefully its already where it should be but we can set it too)
		Uses light sensor, encoders, and limelight to know when it has reached whatever bay it wants to deposit at
			It will be told what bay to go to by the programming driver or like the number of times the button is pressed or something
		Using the PD loop, move the robot until its in the right spot, then use the arm to drop off the hatch

Logger:
	Re use the logger from last year and add Logger calls throughout the code
	Later, if we have extra time, we can improve the Logger functionality

Parser:
	Update the tokens for the 2019 season. Ex: Replace "intake" with "hatch" and "cargo"
	Parse through the auto file line by line
		Read the whole file in as a single string
		Read the first line and if its a command you run it. Ex: if it says drive 10, then run a drive task to move 10 inches
		If its a serial/bundle, skip through the string until you find a "}." Once the number of "}" equals the number of "{," use 
		substrings to recurse and run those commands either in serial or bundle
		Look at whiteboard pic for more information

Write auto code:
	We'll write individual auto files once the parser is complete

SmartDashboard integration:
	Set test values that are changed often (coefficients/constants, motor powers, etc) through the SmartDashboard. The end goal is that 
	the code is constantly feeding these values in from the SmartDashboard, so even if the robot is constantly enabled we can switch 
	the Hatch arm speed from 0.25 to 0.30 and it would update in real time. There would also be a toggle on this feature, so that we 
	don't accidentally change values right before or during a match.

	Set up the SmartDashboard so that we can pick different auto files to run, much like last year

PID Loops:
	Write the loops for the hatch, cargo, turret lock (maybe), etc:
	Tune the loops:
		We can tune them slightly when initially testing, but our main tuning will occur when the robot is finished and we have testing 
		time

Path code:
	It's a mess. Just do your best

Look at all the TODO's in the project and start doing them:
	We never get to this. Maybe this year it'll be different...
	
Turret Lock:
	Use the limelight camera to make the turret (lazy susan) lock onto the vision target regardless of the robot orientation.
	Even if the front of the robot is 30 degrees off from facing forward, we can use limelight to make sure the lazy susan (turret) is 
	still facing forward relative to the vision tape. If the angle offset starts going up, we move the turret. This is a control loop

Config file:
	If desired, you can make a .config file of some sort allowing for quick changes to control layouts.
	The code would read the config files and look for the specified buttons/axis assigned to a specified action, then execute that action
		Ex: A variable holds the button ID which will be used for the hatch arm. It gets the ID from the config file upon robotInit, and if 
		the button with that ID is pressed, it runs the hatch dropoff.

Good Vision:
	-Auto Align:
		-Working with Limelight
			-Account for "wrong" pairs. These are pairs of tape made from two ends of different pairs. They do not line up in front of 
			a target; they line up between targets. If we don't account for these pairs in our detection, we simply account for them in 
			the count of how many pairs we see before some action
	-Color Sensor
		-Wiring them on the very edges of the robot
		-Writing the code to utilize them alongside Limelight and encoders

Auto:
	-Write new auto code:
		-Make new path files
		-Take a ball or hatch to any spot on the bay
			-Dont drop the hatch until the driver confirms the position
			-New naming convention
		-5 Start Positions:
			Level 2: L   R
			Level 1: L M R
	-Shuffleboard integration
	-Use vision code in auto
	-Displaying camera to the Driver Station
	-Improve scripting language
		-Align task?
		-The compiler could be much more sophisticated and robust; low priority though
	
Misc:
	-Create a Programming Phamplet of all the cool stuff we do this year
	-Create an Auto Modes Booklet for all of our auto modes (if we have a lot)